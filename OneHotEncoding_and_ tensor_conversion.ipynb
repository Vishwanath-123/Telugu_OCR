{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4904,"status":"ok","timestamp":1701108179428,"user":{"displayName":"SPARSH GUPTA","userId":"15082271238804493183"},"user_tz":-330},"id":"vImtanK0fkGY"},"outputs":[],"source":["import numpy as np\n","import torch\n","import fasttext"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1701108179430,"user":{"displayName":"SPARSH GUPTA","userId":"15082271238804493183"},"user_tz":-330},"id":"ux4sOo0Wec2A"},"outputs":[],"source":["# characters = ['ఀ', 'ఁ', 'ం', 'ః', 'ఄ', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ',\n","#               'ఌ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'అం', 'అః', 'క', 'ఖ', 'గ', 'ఘ', 'ఙ',\n","#               'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ',\n","#               'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల',\n","#               'ళ', 'ఴ', 'వ', 'శ', 'ష', 'స', 'హ', 'ఽ', 'ా', 'ి', 'ీ', 'ు', 'ూ',\n","#               'ృ', 'ౄ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్', 'ౕ', 'ౖ', 'ౘ', 'ౙ', 'ౚ',\n","#               'ౠ', 'ౡ', 'ౢ', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')',\n","#               '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[',\n","#               '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '1','2', '3', '4', '5', '6', '7', '8', '9', '0', '౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯', 'క్ష']\n","\n","# Mapping_dict = {}\n","# ind = 0\n","# for x in characters:\n","#   Mapping_dict[x] = ind\n","#   ind +=1\n","# print(len(characters))"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9090,"status":"ok","timestamp":1701108576621,"user":{"displayName":"SPARSH GUPTA","userId":"15082271238804493183"},"user_tz":-330},"id":"dW9qgpnlfeGa","outputId":"6dec51ee-006f-4b56-b4e0-dd4dd7839302"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":625,"status":"ok","timestamp":1701108676682,"user":{"displayName":"SPARSH GUPTA","userId":"15082271238804493183"},"user_tz":-330},"id":"ESsh0j3BhAUf","outputId":"b916f55d-f24a-4243-fdb6-e0b3ae238b53"},"outputs":[{"name":"stdout","output_type":"stream","text":["BASE:  {'అ': 1, 'ఆ': 2, 'ఇ': 3, 'ఈ': 4, 'ఉ': 5, 'ఊ': 6, 'ఋ': 7, 'ౠ': 8, 'ఌ': 9, 'ౡ': 10, 'ఎ': 11, 'ఏ': 12, 'ఐ': 13, 'ఒ': 14, 'ఓ': 15, 'ఔ': 16, 'అం': 17, 'అః': 18, 'క': 19, 'ఖ': 20, 'గ': 21, 'ఘ': 22, 'ఙ': 23, 'చ': 24, 'ఛ': 25, 'జ': 26, 'ఝ': 27, 'ఞ': 28, 'ట': 29, 'ఠ': 30, 'డ': 31, 'ఢ': 32, 'ణ': 33, 'త': 34, 'థ': 35, 'ద': 36, 'ధ': 37, 'న': 38, 'ప': 39, 'ఫ': 40, 'బ': 41, 'భ': 42, 'మ': 43, 'య': 44, 'ర': 45, 'ల': 46, 'వ': 47, 'శ': 48, 'ష': 49, 'స': 50, 'హ': 51, 'ళ': 52, 'క్ష': 53, 'ఱ': 54, 'ఴ': 55, 'ౘ': 56, 'ౙ': 57, 'ౚ': 58, ' ': 59, '!': 60, '\"': 61, '#': 62, '$': 63, '%': 64, '&': 65, \"'\": 66, '(': 67, ')': 68, '*': 69, '+': 70, ',': 71, '-': 72, '.': 73, '/': 74, ':': 75, ';': 76, '<': 77, '=': 78, '>': 79, '?': 80, '@': 81, '[': 82, '\\\\': 83, ']': 84, '^': 85, '_': 86, '`': 87, '{': 88, '|': 89, '}': 90, '~': 91, '1': 92, '2': 93, '3': 94, '4': 95, '5': 96, '6': 97, '7': 98, '8': 99, '9': 100, '0': 101, 'ఽ': 102, '౦': 103, '౧': 104, '౨': 105, '౩': 106, '౪': 107, '౫': 108, '౬': 109, '౭': 110, '౮': 111, '౯': 112}\n","  VM:  {'ా': 1, 'ి': 2, 'ీ': 3, 'ు': 4, 'ూ': 5, 'ృ': 6, 'ౄ': 7, 'ె': 8, 'ే': 9, 'ై': 10, 'ొ': 11, 'ో': 12, 'ౌ': 13, 'ం': 14, 'ః': 15, 'ఁ': 16, 'ఀ': 17, 'ఄ': 18, 'ౕ': 19, 'ౖ': 20, 'ౢ': 21}\n","  CM:  {'క': 1, 'ఖ': 2, 'గ': 3, 'ఘ': 4, 'ఙ': 5, 'చ': 6, 'ఛ': 7, 'జ': 8, 'ఝ': 9, 'ఞ': 10, 'ట': 11, 'ఠ': 12, 'డ': 13, 'ఢ': 14, 'ణ': 15, 'త': 16, 'థ': 17, 'ద': 18, 'ధ': 19, 'న': 20, 'ప': 21, 'ఫ': 22, 'బ': 23, 'భ': 24, 'మ': 25, 'య': 26, 'ర': 27, 'ల': 28, 'వ': 29, 'శ': 30, 'ష': 31, 'స': 32, 'హ': 33, 'ళ': 34, 'క్ష': 35, 'ఱ': 36, 'ఴ': 37, 'ౘ': 38, 'ౙ': 39, 'ౚ': 40}\n","112\n","21\n","40\n"]}],"source":["acchulu = ['అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ౠ', 'ఌ', 'ౡ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'అం', 'అః']\n","hallulu = ['క', 'ఖ', 'గ', 'ఘ', 'ఙ',\n","           'చ', 'ఛ', 'జ', 'ఝ', 'ఞ',\n","           'ట', 'ఠ', 'డ', 'ఢ', 'ణ',\n","           'త', 'థ', 'ద', 'ధ', 'న',\n","           'ప', 'ఫ', 'బ', 'భ', 'మ',\n","           'య', 'ర', 'ల', 'వ', 'శ', 'ష', 'స', 'హ', 'ళ', 'క్ష', 'ఱ', 'ఴ', 'ౘ', 'ౙ','ౚ']\n","vallulu = ['ా', 'ి', 'ీ', 'ు' , 'ూ', 'ృ', 'ౄ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', 'ం', 'ః', 'ఁ', 'ఀ', 'ఄ', 'ౕ', 'ౖ', 'ౢ' ]\n","connector = ['్']\n","numbers = ['౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯']\n","splcharacters= [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')',\n","              '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[',\n","              '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '1','2', '3', '4', '5', '6', '7', '8', '9', '0', 'ఽ']\n","spl = splcharacters + numbers\n","\n","bases = acchulu + hallulu + spl\n","vms = vallulu\n","cms = hallulu\n","\n","characters = bases+vms+cms+connector\n","\n","base_mapping = {}\n","i = 1\n","for x in bases:\n","  base_mapping[x] = i\n","  i+=1\n","\n","vm_mapping = {}\n","i = 1\n","for x in vms:\n","  vm_mapping[x] = i\n","  i+=1\n","\n","cm_mapping = {}\n","i = 1\n","for x in cms:\n","  cm_mapping[x] = i\n","  i+=1\n","\n","\n","print(\"BASE: \", base_mapping)\n","print(\"  VM: \", vm_mapping)\n","print(\"  CM: \", cm_mapping)\n","\n","print(len(base_mapping))\n","print(len(vm_mapping))\n","print(len(cm_mapping))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["356"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["112 + 4*21 + 4*40"]},{"cell_type":"markdown","metadata":{"id":"Lpjgsdz8aT6s"},"source":["Base can be anything in acchulu and hallulu and spl\n","\n","Vm can be anythng in  vallulu. But we have 3 VM's\n","\n","Cm can be anything in Hallulu. But we have 3 Cm's.\n","\n","For every term there will be a list of len(acchulu) + 3*len(vallulu) + 4*len(hallulu) + len(spl) = 295"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1701108678758,"user":{"displayName":"SPARSH GUPTA","userId":"15082271238804493183"},"user_tz":-330},"id":"_XR6FIS-hqbJ"},"outputs":[],"source":["# load the txt file and read the file line by line.\n","def read_file_lines(filename):\n","    lines = []\n","    try:\n","        with open(filename, 'r') as file:\n","            for line in file:\n","                lines.append(line.strip())  # Remove trailing newline characters\n","    except FileNotFoundError:\n","        print(f\"File '{filename}' not found.\")\n","    except Exception as e:\n","        print(f\"An error occurred: {str(e)}\")\n","\n","    return lines"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1701108681471,"user":{"displayName":"SPARSH GUPTA","userId":"15082271238804493183"},"user_tz":-330},"id":"JWpbCP50f4OB"},"outputs":[],"source":["path = '/home/ocr/teluguOCR/Dataset/labels.txt'\n","lines = read_file_lines(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1701108683723,"user":{"displayName":"SPARSH GUPTA","userId":"15082271238804493183"},"user_tz":-330},"id":"yXgP8KRWjxA8"},"outputs":[],"source":["# creates a list of ductionaries with each dictionary reporesenting a term\n","def wordsDicts(s):\n","  List = []\n","  for i in range(len(s)):\n","    x = s[i]\n","    prev = ''\n","    if i > 0: prev = s[i-1]\n","    #----------------------------------is it a base term-----------------------\n","    if((x in acchulu or x in hallulu)  and prev != connector[0]):\n","      List.append({})\n","      List[-1]['base'] = x\n","    #----------------------------if it is a consonant modifier-----------------\n","    elif x in hallulu and prev == connector[0]:\n","      if(len(List) == 0):\n","        print(x)\n","      if('cm' not in List[-1]): List[-1]['cm'] = []\n","      List[len(List)-1]['cm'].append(x)\n","\n","      #---------------------------if it is a vowel modifier--------------------\n","    elif x in vallulu:\n","      if(len(List) == 0):\n","        print(x)\n","\n","      if('vm' not in List[-1]): List[-1]['vm'] = []\n","      List[len(List)-1]['vm'].append(x)\n","\n","      #----------------------------it is a spl character-----------------------\n","    elif x in spl:\n","      List.append({})\n","      List[len(List)-1]['base'] = x\n","    else:\n","      continue\n","  return List"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1046,"status":"ok","timestamp":1701109637749,"user":{"displayName":"SPARSH GUPTA","userId":"15082271238804493183"},"user_tz":-330},"id":"rtMceXJpF_-k"},"outputs":[],"source":["# def one_hot_encoder(s):\n","#   List = wordsDicts(s)\n","#   onehot = []\n","#   for i in range(len(List)):\n","#     D = List[i]\n","#     onehotbase=  [0 for _ in range(len(acchulu) +  len(hallulu) + len(spl))]\n","#     onehotvm =  [0 for _ in range(len(vallulu))]\n","#     onehotcm =  [0 for _ in range(len(hallulu))]   \n","#     onehotbase[base_mapping[D['base']]-1] = 1\n","#     if('vm' in D):\n","#       for j in D['vm']:\n","#         onehotvm[vm_mapping[j]-1] = 1\n","#     if('cm' in D):\n","#       for j in D['cm']:\n","#         onehotcm[cm_mapping[j]-1] = 1\n","#     onehoti = [0, 0] + onehotbase + onehotvm + onehotcm # length of 112 + 21 + 40 + 2 = 175\n","#     onehot.append(onehoti)\n","#   return onehot\n","\n","# def One_Hot_Decoder(List):\n","#   x = \"\"\n","#   for onehoti in List:\n","#     for i in range(0, 112):\n","#       if onehoti[i+2] == 1:\n","#         x += bases[i]\n","#     for i in range(133, 173):\n","#       if onehoti[i+2] == 1:\n","#         x += connector[0] \n","#         x += cms[i-133]\n","#     for i in range(112,133):\n","#       if onehoti[i+2] == 1:\n","#         x += vms[i-112]\n","#   return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# def one_hot_encoder(s):\n","#   List = wordsDicts(s)\n","#   onehot = []\n","#   for i in range(len(List)):\n","#     D = List[i]\n","#     onehotbase= [0]\n","#     onehotvm = [0, 0, 0]\n","#     onehotcm = [0, 0, 0]\n","#     onehotbase[0] = base_mapping[D['base']]\n","#     if('vm' in D):\n","#       i = 1\n","#       for j in range(len(D['vm'])):\n","#         if i == 1:\n","#           onehotvm[0] = vm_mapping[D['vm'][j]]\n","#         if i == 2:\n","#           onehotvm[1] = vm_mapping[D['vm'][j]]\n","#         if i == 3:\n","#           onehotvm[2] = vm_mapping[D['vm'][j]]\n","#         i += 1\n","#     if('cm' in D):\n","#       i = 1\n","#       for j in range(len(D['cm'])):\n","#         if(i == 1):\n","#           onehotcm[0] = cm_mapping[D['cm'][j]]\n","#         if(i == 2):\n","#           onehotcm[1] = cm_mapping[D['cm'][j]]\n","#         if(i == 3):\n","#           onehotcm[2] = cm_mapping[D['cm'][j]]\n","#         i+=1\n","#     onehoti = onehotbase + onehotvm + onehotcm # length of 7\n","#     onehot.append(onehoti)\n","#   return onehot\n","\n","# def One_Hot_Decoder(List):\n","#   x = \"\"\n","#   for term in List:\n","#     x += bases[term[0]-1]\n","#     if term[4] != 0:\n","#       x += connector[0] \n","#       x += cms[term[4]-1]\n","#     if term[5] != 0:\n","#       x += connector[0] \n","#       x += cms[term[5]-1]\n","#     if term[6] != 0:\n","#       x += connector[0] \n","#       x += cms[term[6]-1]\n","    \n","#     if term[1] != 0:\n","#       x += vms[term[1]-1]\n","#     if term[2] != 0:\n","#       x += vms[term[2]-1]\n","#     if term[3] != 0:\n","#       x += vms[term[3]-1]\n","\n","#   return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# start_token = torch.tensor([0 for _ in range(7)], dtype = torch.long)\n","# end_token = torch.tensor([150 for _ in range(7)], dtype = torch.long)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lines = read_file_lines(path)\n","# OutLabelDir = \"/home/ocr/teluguOCR/Dataset/Label_tensors\"\n","# num = 1\n","# ind = 0\n","# LineTensor = torch.zeros(1000, 350, 7).long()\n","\n","# print(LineTensor[:].shape)\n","\n","# for i in range(len(Lines)):\n","#   l = Lines[i]\n","#   encoded = one_hot_encoder(l)  \n","  \n","#   if len(encoded) == 0:\n","#     ind += 1\n","#     continue\n","\n","#   Tensor_encoded = torch.tensor(encoded, dtype=torch.long)\n","#   LineTensor[ind][0][:] = start_token[:]\n","#   LineTensor[ind][1:len(encoded)+1][:] = Tensor_encoded[:len(encoded)][:]\n","#   LineTensor[ind][len(encoded)+1][:] = end_token[:]\n","#   ind += 1\n","\n","#   if ind == 1000:\n","#     print(\"saved file: \", num)\n","#     print(type(LineTensor))\n","#     torch.save(LineTensor, '/home/ocr/teluguOCR/Dataset/Label_tensors/Label_Tensor' + str(num) + '.pt')\n","#     num+=1\n","#     ind = 0\n","#     LineTensor = torch.zeros(1000, 350, 7).long\n","\n","# if ind != 0:\n","#   print(\"saved file: \", num)\n","#   torch.save(LineTensor, '/home/ocr/teluguOCR/Dataset/Label_tensors/Label_Tensor' + str(num) + '.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"aborted","timestamp":1701108272237,"user":{"displayName":"SPARSH GUPTA","userId":"15082271238804493183"},"user_tz":-330},"id":"vEDbqkWDhvPz"},"outputs":[],"source":["Lines = read_file_lines(path)\n","OutLabelDir = \"/home/ocr/teluguOCR/Dataset/Label_tensors\"\n","num = 1\n","ind = 0\n","LineTensor = torch.zeros(1000, 350, 100)\n","print(LineTensor[:].shape)\n","\n","i = 0\n","Missed = [16383]\n","for i in range(len(Lines)):\n","  l = Lines[i]\n","  encoded = one_hot_encoder(l)  \n","  if len(encoded) == 0:\n","    ind += 1\n","    continue\n","\n","  Tensor_encoded = torch.Tensor(encoded)\n","\n","  # print(LineTensor.shape)\n","  # print(Tensor_encoded.shape)\n","  \n","  LineTensor[ind][1:len(encoded)+1][:] = Tensor_encoded[:len(encoded)][:]\n","  LineTensor[ind][0][0] = 1\n","  LineTensor[ind][len(encoded)+1][1] = 1\n","  ind += 1\n","\n","  if ind == 1000:\n","    print(\"saved file: \", num)\n","    torch.save(LineTensor, '/home/ocr/teluguOCR/Dataset/Label_tensors/Label_Tensor' + str(num) + '.pt')\n","    num+=1\n","    ind = 0\n","    LineTensor = torch.zeros(1000, 350, 175)\n","\n","if ind != 0:\n","  print(\"saved file: \", num)\n","  torch.save(LineTensor, '/home/ocr/teluguOCR/Dataset/Label_tensors/Label_Tensor' + str(num) + '.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["label = torch.load(\"/home/ocr/teluguOCR/Dataset/Label_tensors/Label_Tensor1.pt\")\n","lines = read_file_lines(path)\n","\n","for i in range(175):\n","    if(label[0][1][i] == 1):\n","        print(i)\n","\n","print()\n","print(lines[1])\n","for i in range(350):\n","    if(torch.all(label[1][i] == torch.ones(175))):\n","        print(i)"]},{"cell_type":"markdown","metadata":{"id":"mTm1uVpYeXd7"},"source":["Images to Tensors conversion."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1701108272238,"user":{"displayName":"SPARSH GUPTA","userId":"15082271238804493183"},"user_tz":-330},"id":"0BZQ-aWfeXO8"},"outputs":[],"source":["import torch\n","from torchvision import transforms\n","from PIL import Image\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython.display import display\n","\n","dir = \"/home/ocr/teluguOCR/Dataset/Noised_Images\"\n","Outdir = \"/home/ocr/teluguOCR/Dataset/NoisedImages\"\n","\n","convert_to_tensor = transforms.ToTensor()\n","\n","cnt = 0\n","while True:\n","  subFolder = dir\n","  Image_Tensors = torch.zeros(1000, 1, 32, 32)\n","  flag = False\n","  for j in range(1, 1001):\n","    image = subFolder + \"/Image\" + str(cnt*1000 + j) + \".pt\"\n","    if os.path.isfile(image) == False:\n","      flag = True\n","      break\n","    Im = torch.load(image)\n","\n","    Im = np.array(Im)\n","    Im = Image.fromarray(Im[0])\n","    Im = Im.resize((32, 32))\n","    Im = np.array(Im)\n","    Im[Im > 1] = 1\n","    Im[Im < 0] = 0\n","    Im = 1 - Im\n","    # # create a 3 channel image\n","    # Img = np.zeros((224, 224, 3))\n","    # Img[:, :, 0] = Im\n","    # Img[:, :, 1] = Im\n","    # Img[:, :, 2] = Im\n","    \n","    Tensor = convert_to_tensor(Im)\n","    # print(Tensor.shape)\n","    Image_Tensors[j-1][0] = Tensor\n","  print(\"saved file: \", cnt)\n","  if(torch.max(Image_Tensors) > 1):\n","    print(\"greater than 1 at: \", cnt+1)\n","  torch.save(Image_Tensors, Outdir + \"/Tensor\" + str(cnt+1) + \".pt\")\n","  del Image_Tensors\n","  cnt += 1\n","  if flag == True:\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Im = torch.load(\"/home/ocr/teluguOCR/Dataset/NoisedImages/Tensor30.pt\")\n","# print(Im.shape)\n","# plt.imshow(Im[0], cmap='gray')\n","# plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["CHECKING THE DATA"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load the image and label tensors\n","import torch\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","Images = \"/home/ocr/teluguOCR/Dataset/NoisedImages/Tensor20.pt\"\n","Labels = \"/home/ocr/teluguOCR/Dataset/Label_tensors/Label_Tensor20.pt\"\n","\n","ImageTensor = np.array(torch.load(Images))\n","LabelTensor = np.array(torch.load(Labels))\n","labelstxtfile = open(\"/home/ocr/teluguOCR/Dataset/labels.txt\", \"r\")\n","labels = labelstxtfile.readlines()\n","labelstxtfile.close()\n","\n","print(ImageTensor.shape)\n","print(LabelTensor.shape)\n","\n","print(LabelTensor[0])\n","# NUMBER  OF ONES IN label tensor[0]\n","# print(np.sum(LabelTensor[0][0]))\n","# for i in range(302):\n","#     if(LabelTensor[0][0][i] == 1):\n","#         print(i)\n","\n","for i in range(10):\n","    decoded = One_Hot_Decoder(LabelTensor[i])\n","    # print(labels[29000 + i])\n","    print(decoded)\n","    plt.imshow(ImageTensor[i][0], cmap='gray')\n","    plt.show()\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","Im = torch.load(\"/home/ocr/teluguOCR/Dataset/Noised_Images/Image5.pt\")\n","\n","Im = np.array(Im)\n","Im = Image.fromarray(Im[0])\n","Im = Im.resize((224, 224))\n","Im = np.array(Im)\n","Im[Im > 1] = 1\n","Im[Im < 0] = 0\n","# create a 3 channel image\n","Img = np.zeros((224, 224, 3))\n","Img[:, :, 0] = Im\n","Img[:, :, 1] = Im\n","Img[:, :, 2] = Im\n","\n","plt.imshow(Img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# I = Image.open(\"/home/ocr/teluguOCR/Dataset/Images_of_texts/Image_20.png\")\n","# # print(I.shape)\n","# plt.imshow(I)\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","# starting token for each line\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","starting_token = torch.zeros(175)\n","starting_token[0] = starting_token[1] = 1\n","starting_token = starting_token.to(device)\n","\n","t = torch.tensor(s1_encoded[0], dtype=torch.float32).to(device)\n","# t1 = torch.tensor(s1_encoded[1], dtype=torch.float32).to(device)\n","\n","# print(t)\n","\n","# t = starting_token\n","t1 = starting_token\n","# print(t1)\n","critereon = nn.BCEWithLogitsLoss().cuda() if torch.cuda.is_available() else nn.BCEWithLogitsLoss()\n","\n","classes = torch.ones(175)\n","classes[0] = classes[1] = 1000\n","\n","critereon = nn.MultiLabelMarginLoss(weight=classes, reduction='mean').cuda() if torch.cuda.is_available() else nn.MultiLabelMarginLoss(weight=classes, reduction='mean')\n","\n","\n","print(torch.all(torch.eq(t1, t1)))\n","l = critereon(t, t1)\n","\n","# l  = critereon(t1[:113], t[:113])\n","# l += critereon(t1[135:157], t[135:157])\n","# l += critereon(t1[157:179], t[157:179])\n","# l += critereon(t1[179:220], t[179:220])\n","# l += critereon(t1[220:261], t[220:261])\n","# l += critereon(t1[261:], t[261:])\n","\n","print(l)\n","\n","print(torch.sum(t1), critereon(t1, t1))\n","print(torch.sum(t), critereon(t, t))\n","print(critereon(t.__reversed__(), t1.__reversed__()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["end_token = torch.ones(302)\n","print(torch.argmax(end_token))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","truth = torch.FloatTensor([1, 0])\n","pred = torch.FloatTensor([100, -100])\n","\n","critereon = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n","\n","print(critereon(pred, truth))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(nn.CrossEntropyLoss()(pred, torch.argmax(truth)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import matplotlib.pyplot as plt\n","import numpy as np \n","\n","image = torch.load(\"/home/ocr/teluguOCR/Dataset/NoisedImages/Tensor1.pt\")[0][0]\n","img = np.array(image)\n","print(img.shape)\n","\n","# img = 1 - img\n","\n","with open(\"../output.txt\", 'w') as f:\n","    for a in img:\n","        for b in a:\n","            f.write(str(b) + \" \")\n","        f.write('\\n')\n","\n","plt.imshow(img, cmap='gray')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","label = torch.load(\"../teluguOCR/Dataset/Batch_Label_Tensors/Label1.pt\")\n","print(label.shape)\n","\n","label_ = label[0]\n","negative = torch.ones_like(label_)\n","positive = label[1]\n","\n","critereon = nn.TripletMarginLoss(margin=1e6, p=2).cuda() if torch.cuda.is_available() else nn.TripletMarginLoss(margin=1.0, p=2)\n","\n","print(critereon(label_, positive, negative))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
