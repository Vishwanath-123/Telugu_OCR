{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import fasttext\n",
    "\n",
    "images_dir = '../teluguOCR/Dataset/Noised_Images/Image'\n",
    "Labels_dir = \"../teluguOCR/Dataset/strings.txt\"\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the txt file and read the file line by line.\n",
    "def read_file_lines(filename):\n",
    "    lines = []\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                lines.append(line.strip())  # Remove trailing newline characters\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filename}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "కా\n"
     ]
    }
   ],
   "source": [
    "print('క' + 'ా')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 19 36\n"
     ]
    }
   ],
   "source": [
    "acchulu = ['అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ౠ', 'ఌ', 'ౡ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'అం', 'అః']\n",
    "hallulu = ['క', 'ఖ', 'గ', 'ఘ', 'ఙ',\n",
    "           'చ', 'ఛ', 'జ', 'ఝ', 'ఞ',\n",
    "           'ట', 'ఠ', 'డ', 'ఢ', 'ణ',\n",
    "           'త', 'థ', 'ద', 'ధ', 'న',\n",
    "           'ప', 'ఫ', 'బ', 'భ', 'మ',\n",
    "           'య', 'ర', 'ల', 'వ', 'శ', 'ష', 'స', 'హ', 'ళ', 'క్ష', 'ఱ']\n",
    "vallulu = ['ా', 'ి', 'ీ', 'ు' , 'ూ', 'ృ', 'ౄ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', 'ం', 'ః', 'ఁ', 'ౕ', 'ౖ', 'ౢ' ]\n",
    "connector = ['్']\n",
    "numbers = ['౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯']\n",
    "splcharacters= [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')',\n",
    "              '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[',\n",
    "              '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '1','2', '3', '4', '5', '6', '7', '8', '9', '0', 'ఽ']\n",
    "spl = splcharacters + numbers\n",
    "\n",
    "bases = acchulu + hallulu + spl\n",
    "vms = vallulu\n",
    "cms = hallulu\n",
    "\n",
    "print(len(bases), len(vms), len(cms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acchulu = ['అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ౠ', 'ఌ', 'ౡ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'అం', 'అః']\n",
    "hallulu = ['క', 'ఖ', 'గ', 'ఘ', 'ఙ',\n",
    "           'చ', 'ఛ', 'జ', 'ఝ', 'ఞ',\n",
    "           'ట', 'ఠ', 'డ', 'ఢ', 'ణ',\n",
    "           'త', 'థ', 'ద', 'ధ', 'న',\n",
    "           'ప', 'ఫ', 'బ', 'భ', 'మ',\n",
    "           'య', 'ర', 'ల', 'వ', 'శ', 'ష', 'స', 'హ', 'ళ', 'క్ష', 'ఱ', 'ఴ', 'ౘ', 'ౙ','ౚ']\n",
    "vallulu = ['ా', 'ి', 'ీ', 'ు' , 'ూ', 'ృ', 'ౄ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', 'ం', 'ః', 'ఁ', 'ఀ', 'ఄ', 'ౕ', 'ౖ', 'ౢ' ]\n",
    "connector = ['్']\n",
    "numbers = ['౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯']\n",
    "splcharacters= [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')',\n",
    "              '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[',\n",
    "              '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '1','2', '3', '4', '5', '6', '7', '8', '9', '0', 'ఽ']\n",
    "spl = splcharacters + numbers\n",
    "\n",
    "bases = acchulu + hallulu + spl\n",
    "vms = vallulu\n",
    "cms = hallulu\n",
    "\n",
    "characters = bases+vms+cms+connector\n",
    "\n",
    "base_mapping = {}\n",
    "i = 2\n",
    "for x in bases:\n",
    "  base_mapping[x] = i\n",
    "  i+=1\n",
    "\n",
    "vm_mapping = {}\n",
    "i = 2\n",
    "for x in vms:\n",
    "  vm_mapping[x] = i\n",
    "  i+=1\n",
    "\n",
    "cm_mapping = {}\n",
    "i = 2\n",
    "for x in cms:\n",
    "  cm_mapping[x] = i\n",
    "  i+=1\n",
    "\n",
    "  \n",
    "# creates a list of ductionaries with each dictionary reporesenting a term\n",
    "def wordsDicts(s):\n",
    "  List = []\n",
    "  for i in range(len(s)):\n",
    "    x = s[i]\n",
    "    prev = ''\n",
    "    if i > 0: prev = s[i-1]\n",
    "    #----------------------------------is it a base term-----------------------\n",
    "    if((x in acchulu or x in hallulu)  and prev != connector[0]):\n",
    "      List.append({})\n",
    "      List[-1]['base'] = x\n",
    "    #----------------------------if it is a consonant modifier-----------------\n",
    "    elif x in hallulu and prev == connector[0]:\n",
    "      if(len(List) == 0):\n",
    "        print(x)\n",
    "      if('cm' not in List[-1]): List[-1]['cm'] = []\n",
    "      List[len(List)-1]['cm'].append(x)\n",
    "\n",
    "      #---------------------------if it is a vowel modifier--------------------\n",
    "    elif x in vallulu:\n",
    "      if(len(List) == 0):\n",
    "        print(x)\n",
    "\n",
    "      if('vm' not in List[-1]): List[-1]['vm'] = []\n",
    "      List[len(List)-1]['vm'].append(x)\n",
    "\n",
    "      #----------------------------it is a spl character-----------------------\n",
    "    elif x in spl:\n",
    "      List.append({})\n",
    "      List[len(List)-1]['base'] = x\n",
    "    else:\n",
    "      continue\n",
    "  return List\n",
    "\n",
    "# def one_hot_encoder(s):\n",
    "#   List = wordsDicts(s)\n",
    "#   onehot = []\n",
    "#   for i in range(len(List)):\n",
    "#     D = List[i]\n",
    "#     onehotbase=  [0 for _ in range(len(acchulu) +  len(hallulu) + len(spl))]\n",
    "#     onehotvm1 =  [0 for _ in range(len(vallulu))]\n",
    "#     onehotvm2 =  [0 for _ in range(len(vallulu))]\n",
    "#     onehotvm3 =  [0 for _ in range(len(vallulu))]\n",
    "#     onehotvm4 =  [0 for _ in range(len(vallulu))]\n",
    "\n",
    "#     onehotcm1 =  [0 for _ in range(len(hallulu))]   \n",
    "#     onehotcm2 =  [0 for _ in range(len(hallulu))]   \n",
    "#     onehotcm3 =  [0 for _ in range(len(hallulu))]   \n",
    "#     onehotcm4 =  [0 for _ in range(len(hallulu))]   \n",
    "\n",
    "#     onehotbase[base_mapping[D['base']]-1] = 1\n",
    "\n",
    "#     it = 1\n",
    "#     if('vm' in D):\n",
    "#       for j in D['vm']:\n",
    "#         if it == 1:\n",
    "#           onehotvm1[vm_mapping[j]-1] = 1\n",
    "#         elif it == 2:\n",
    "#           onehotvm2[vm_mapping[j]-1] = 1\n",
    "#         elif it == 3:\n",
    "#           onehotvm3[vm_mapping[j]-1] = 1\n",
    "#         elif it == 4:\n",
    "#           onehotvm4[vm_mapping[j]-1] = 1\n",
    "#         it += 1\n",
    "    \n",
    "#     it = 1\n",
    "#     if('cm' in D):\n",
    "#       for j in D['cm']:\n",
    "#         if it == 1:\n",
    "#           onehotcm1[cm_mapping[j]-1] = 1\n",
    "#         elif it == 2:\n",
    "#           onehotcm2[cm_mapping[j]-1] = 1\n",
    "#         elif it == 3:\n",
    "#           onehotcm3[cm_mapping[j]-1] = 1\n",
    "#         elif it == 4:\n",
    "#           onehotcm4[cm_mapping[j]-1] = 1\n",
    "#         it += 1\n",
    "\n",
    "\n",
    "#     onehoti = onehotbase + onehotvm1 + onehotvm2 + onehotvm3 + onehotvm4 + onehotcm1 + onehotcm2 + onehotcm3 + onehotcm4 #size 112 + 4*21 + 4*40 = 356\n",
    "#     onehot.append(onehoti)\n",
    "#   encoded = torch.tensor(onehot).float().to(device)\n",
    "#   return encoded\n",
    "\n",
    "# def One_Hot_Decoder(List):\n",
    "#   x = \"\"\n",
    "#   for onehoti in List:\n",
    "#     for i in range(0, 112):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += bases[i]\n",
    "\n",
    "#     for i in range(196, 236):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += connector[0]\n",
    "#         x += cms[i-196]\n",
    "#     for i in range(236, 276):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += connector[0]\n",
    "#         x += cms[i-236]\n",
    "#     for i in range(276, 316):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += connector[0]\n",
    "#         x += cms[i-276]\n",
    "#     for i in range(316, 356):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += connector[0]\n",
    "#         x += cms[i-316]\n",
    "\n",
    "#     for i in range(112, 133):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += vms[i-112]\n",
    "#     for i in range(133, 154):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += vms[i-133]\n",
    "#     for i in range(154, 175):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += vms[i-154]\n",
    "#     for i in range(175, 196):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += vms[i-175]\n",
    "#   return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_encoding(s):\n",
    "  List = wordsDicts(s)\n",
    "  onehot = []\n",
    "  for i in range(len(List)):\n",
    "    D = List[i]\n",
    "    onehotbase=  [1]\n",
    "    onehotvm1 =  [1]\n",
    "    onehotvm2 =  [1]\n",
    "    onehotvm3 =  [1]\n",
    "    onehotvm4 =  [1]\n",
    "    onehotcm1 =  [1]\n",
    "    onehotcm2 =  [1]\n",
    "    onehotcm3 =  [1]\n",
    "    onehotcm4 =  [1]\n",
    "\n",
    "\n",
    "    onehotbase[0] = base_mapping[D['base']]\n",
    "\n",
    "    it = 1\n",
    "    if('vm' in D):\n",
    "      for j in D['vm']:\n",
    "        if it == 1:\n",
    "          onehotvm1[0] = vm_mapping[j]\n",
    "        elif it == 2:\n",
    "          onehotvm2[0] = vm_mapping[j]\n",
    "        elif it == 3:\n",
    "          onehotvm3[0] = vm_mapping[j]\n",
    "        elif it == 4:\n",
    "          onehotvm4[0] = vm_mapping[j]\n",
    "        it += 1\n",
    "    \n",
    "    it = 1\n",
    "    if('cm' in D):\n",
    "      for j in D['cm']:\n",
    "        if it == 1:\n",
    "          onehotcm1[0] = cm_mapping[j]\n",
    "        elif it == 2:\n",
    "          onehotcm2[0] = cm_mapping[j]\n",
    "        elif it == 3:\n",
    "          onehotcm3[0] = cm_mapping[j]\n",
    "        elif it == 4:\n",
    "          onehotcm4[0] = cm_mapping[j]\n",
    "        it += 1\n",
    "    onehoti = onehotbase + onehotvm1 + onehotvm2 + onehotvm3 + onehotvm4 + onehotcm1 + onehotcm2 + onehotcm3 + onehotcm4 #size 112 + 4*21 + 4*40 = 356\n",
    "    onehot.append(onehoti)\n",
    "  return onehot\n",
    "\n",
    "def index_decoder(List):\n",
    "  x = \"\"\n",
    "  for onehoti in List:\n",
    "    if onehoti[0] != 1 and onehoti[0] != 0:\n",
    "      x += bases[onehoti[0]-2]\n",
    "\n",
    "    if onehoti[5] != 1 and onehoti[5] != 0:\n",
    "      x += connector[0]\n",
    "      x += cms[onehoti[5]-2]\n",
    "    if onehoti[6] != 1 and onehoti[6] != 0:\n",
    "      x += connector[0]\n",
    "      x += cms[onehoti[6]-2]\n",
    "    if onehoti[7] != 1 and onehoti[7] != 0:\n",
    "      x += connector[0]\n",
    "      x += cms[onehoti[7]-2]\n",
    "    if onehoti[8] != 1 and onehoti[8] != 0:\n",
    "      x += connector[0]\n",
    "      x += cms[onehoti[8]-2]\n",
    "\n",
    "    if onehoti[1] != 1 and onehoti[1] != 0:\n",
    "      x += vms[onehoti[1]-2]\n",
    "    if onehoti[2] != 1 and onehoti[2] != 0:\n",
    "      x += vms[onehoti[2]-2]\n",
    "    if onehoti[3] != 1 and onehoti[3] != 0:\n",
    "      x += vms[onehoti[3]-2]\n",
    "    if onehoti[4] != 1 and onehoti[4] != 0:\n",
    "      x += vms[onehoti[4]-2]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'అందరికి శుభాకాంక్షలు'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"అందరికి శుభాకాంక్షలు\"\n",
    "encoded = index_encoding(s)\n",
    "index_decoder(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches = os.listdir(\"../teluguOCR/Dataset/batches/\")\n",
    "# number_of_images = 0\n",
    "\n",
    "# num = 1\n",
    "# for i in range(300):\n",
    "#     batch = 'batch' + str(i)\n",
    "#     if batch not in batches:\n",
    "#         continue\n",
    "#     print(num, \" Done \", batch)\n",
    "#     path = os.path.join(\"../teluguOCR/Dataset/batches/\", batch)\n",
    "\n",
    "#     image_paths = os.listdir(path + \"/images\")\n",
    "#     if len(image_paths) == 0:\n",
    "#         continue\n",
    "#     image_sizes = []\n",
    "#     for image_path in image_paths:\n",
    "#         image = torch.load(path + \"/images/\" + image_path)\n",
    "#         image_sizes.append(image.shape[2])\n",
    "#     max_size = max(image_sizes)\n",
    "\n",
    "#     # round off to next 100\n",
    "#     max_size = (max_size // 100 + 1) * 100\n",
    "    \n",
    "#     # create a tensor of size (batch_size, 1, 30, max_size) and pad the images\n",
    "#     batch_images = torch.zeros(len(image_paths), 30, max_size)\n",
    "#     for i in range(len(image_paths)):\n",
    "#         image = torch.load(path + \"/images/image_\" + str(i+1) + \".pt\")\n",
    "#         batch_images[i, :, :image.shape[2]] = image[0, :, :]\n",
    "    \n",
    "#     batch_images = batch_images.to(device)\n",
    "\n",
    "#     # width = 15\n",
    "#     # stride = 5\n",
    "#     total_cropped_images = []\n",
    "#     for i in range(batch_images.shape[0]):\n",
    "#         # cropped_images = []\n",
    "#         image = batch_images[i, :, :]\n",
    "#         lengths.append(image.shape[1])\n",
    "#         if image.shape[1] > 1200:\n",
    "#             continue\n",
    "#         img = Image.fromarray(image.numpy())\n",
    "#         img = img.resize((image.shape[1], image.shape[0]//2))\n",
    "#         image = torch.tensor(np.array(img))\n",
    "#         f_image = torch.zeros(15, 1200)\n",
    "#         f_image[:, :image.shape[1]] = image[:, :]\n",
    "#         total_cropped_images.append(f_image)\n",
    "#         number_of_images += 1\n",
    "#     if len(total_cropped_images) == 0:\n",
    "#         continue\n",
    "#     total_cropped_images = torch.stack(total_cropped_images)\n",
    "#     total_cropped_images = total_cropped_images.to(device)\n",
    "#     torch.save(total_cropped_images, \"/home/ocr/teluguOCR/Dataset/Batch_Image_Tensors/image_tesor\"+str(num)+\".pt\")\n",
    "\n",
    "#     # create a tensor for labels\n",
    "#     labels = read_file_lines(path + \"/label.txt\")\n",
    "#     encoded_labels = []\n",
    "#     for label in labels:\n",
    "#         encoded = torch.tensor(index_encoding(label)).to(device)\n",
    "#         encoded_labels.append(encoded)\n",
    "#     encoded_labels = torch.stack(encoded_labels)\n",
    "#     torch.save(encoded_labels, \"/home/ocr/teluguOCR/Dataset/Batch_Label_Tensors/label_tensor\"+str(num)+\".pt\")\n",
    "\n",
    "#     num += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(number_of_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(max(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plotting the frequency of lengths\n",
    "# plt.hist(lengths, bins=20)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greater_than_600 = 0\n",
    "# less_than_600 = 0\n",
    "\n",
    "# for l in lengths:\n",
    "#     if l > 1000:\n",
    "#         greater_than_600 += 1\n",
    "#     else:\n",
    "#         less_than_600 += 1\n",
    "\n",
    "# print(greater_than_600)\n",
    "# print(less_than_600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = torch.load(\"/home/ocr/teluguOCR/Dataset/batches/batch41/images/image_1.pt\")\n",
    "\n",
    "# plt.imshow(image[0, :, 2:20], cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# batches_image = torch.zeros(1, 30, 1000)\n",
    "# batches_image[0, :, :image.shape[2]-4] = image[0, :, 2:-2]\n",
    "# batches_image = batches_image.to(device)\n",
    "# width = 20\n",
    "# stride = 10\n",
    "\n",
    "# cropped_images = []\n",
    "# for i in range(0, 1000-width, stride):\n",
    "#     cropped_images.append(batches_image[:, :, i:i+width])\n",
    "# cropped_images = torch.stack(cropped_images)\n",
    "\n",
    "# plt.imshow(cropped_images[0, 0, :, :], cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# images = torch.load(\"/home/ocr/teluguOCR/Dataset/Batch_Image_Tensors/image_tesor45.pt\")\n",
    "# labels = torch.load(\"/home/ocr/teluguOCR/Dataset/Batch_Label_Tensors/label_tensor45.pt\")\n",
    "\n",
    "# print(images.shape)\n",
    "# print(labels.shape)\n",
    "\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(images[0, :, 20:60], cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# decoded = index_decoder(labels[0])\n",
    "# print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_num in range(1, 350):\n",
    "    \n",
    "#     Images_dir = \"../teluguOCR/Dataset/batches/batch\" + str(batch_num) + \"/images/\"\n",
    "#     Labels_dir = \"../teluguOCR/Dataset/batches/batch\" + str(batch_num) + \"/label.txt\"\n",
    "#     if(not os.path.exists(Images_dir)):\n",
    "#         continue\n",
    "#     labels = read_file_lines(Labels_dir)\n",
    "#     lengths = [len(one_hot_encoder(i)) for i in labels]\n",
    "#     print(batch_num, np.unique(lengths, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = \"ఉప త్వాగ్నే దివేదివే దోషావస్తర్ధియా వయం\"\n",
    "# print(len(one_hot_encoder(s)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 376])\n"
     ]
    }
   ],
   "source": [
    "image = torch.load(\"../teluguOCR/Dataset/Noised_Images/Image1.pt\")\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches_list = os.listdir(\"../teluguOCR/Dataset/batches/\")\n",
    "# ind = 1\n",
    "# for batch in batches_list:\n",
    "#     print(ind)\n",
    "#     # for labels\n",
    "#     labels = read_file_lines(\"../teluguOCR/Dataset/batches/\" + batch + \"/label.txt\")\n",
    "#     length = len(wordsDicts(labels[0]))\n",
    "#     batch_label_torch = torch.zeros(len(labels), length+2, 358)\n",
    "#     indx = 0\n",
    "#     for label in labels:\n",
    "#         encoded = one_hot_encoder(label)\n",
    "#         batch_label_torch[indx] = encoded\n",
    "#         indx += 1\n",
    "#     torch.save(batch_label_torch, \"/home/ocr/teluguOCR/Dataset/Batch_Label_Tensors/Label\" + str(ind) + \".pt\")\n",
    "\n",
    "#     # for images\n",
    "#     images_list = os.listdir(\"../teluguOCR/Dataset/batches/\" + batch + \"/images/\")\n",
    "#     batch_image_torch = torch.zeros(len(images_list), 1, 30, 500)\n",
    "#     indx = 0\n",
    "#     for image in images_list:\n",
    "#         IMG = torch.load(\"../teluguOCR/Dataset/batches/\" + batch + \"/images/\" + image)\n",
    "#         IMG[IMG > 1] = 1\n",
    "#         IMG[IMG < 0] = 0\n",
    "#         IMG= np.round(IMG*255)\n",
    "#         batch_image_torch[indx] = IMG\n",
    "#         indx += 1\n",
    "#     torch.save(batch_image_torch, \"/home/ocr/teluguOCR/Dataset/Batch_Image_Tensors/Image\" + str(ind) + \".pt\")\n",
    "#     print(\"Batch \" + str(ind) + \" done\")\n",
    "#     ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  | to |  200  done\n",
      "200  | to |  300  done\n",
      "300  | to |  400  done\n",
      "400  | to |  500  done\n",
      "500  | to |  600  done\n",
      "600  | to |  700  done\n",
      "700  | to |  800  done\n",
      "800  | to |  900  done\n",
      "900  | to |  1000  done\n",
      "1000  | to |  1100  done\n",
      "1100  | to |  1200  done\n",
      "1200  | to |  1300  done\n",
      "1300  | to |  1400  done\n",
      "1400  | to |  1500  done\n",
      "1500  | to |  1600  done\n",
      "1600  | to |  1700  done\n",
      "1700  | to |  1800  done\n",
      "1800  | to |  1900  done\n",
      "1900  | to |  2000  done\n",
      "2000  | to |  2100  done\n",
      "2100  | to |  2200  done\n",
      "2200  | to |  2300  done\n",
      "2300  | to |  2400  done\n",
      "2400  | to |  2500  done\n",
      "2500  | to |  2600  done\n",
      "2600  | to |  2700  done\n",
      "2700  | to |  2800  done\n",
      "2800  | to |  2900  done\n",
      "2900  | to |  3000  done\n",
      "3000  | to |  3100  done\n",
      "3100  | to |  3200  done\n",
      "3200  | to |  3300  done\n",
      "3300  | to |  3400  done\n",
      "3400  | to |  3500  done\n",
      "3500  | to |  3600  done\n",
      "3600  | to |  3700  done\n",
      "3700  | to |  3800  done\n",
      "3800  | to |  3900  done\n",
      "3900  | to |  4000  done\n",
      "4000  | to |  4100  done\n",
      "4100  | to |  4200  done\n",
      "4200  | to |  4300  done\n",
      "4300  | to |  4400  done\n",
      "4400  | to |  4500  done\n",
      "4500  | to |  4600  done\n",
      "4600  | to |  4700  done\n",
      "4700  | to |  4800  done\n",
      "4800  | to |  4900  done\n",
      "4900  | to |  5000  done\n",
      "5000  | to |  5100  done\n",
      "5100  | to |  5200  done\n",
      "5200  | to |  5300  done\n",
      "5300  | to |  5400  done\n",
      "5400  | to |  5500  done\n",
      "5500  | to |  5600  done\n",
      "5600  | to |  5700  done\n",
      "5700  | to |  5800  done\n",
      "5800  | to |  5900  done\n",
      "5900  | to |  6000  done\n",
      "6000  | to |  6100  done\n",
      "6100  | to |  6200  done\n",
      "6200  | to |  6300  done\n",
      "6300  | to |  6400  done\n",
      "6400  | to |  6500  done\n",
      "6500  | to |  6600  done\n",
      "6600  | to |  6700  done\n",
      "6700  | to |  6800  done\n",
      "6800  | to |  6900  done\n",
      "6900  | to |  7000  done\n",
      "7000  | to |  7100  done\n",
      "7100  | to |  7200  done\n",
      "7200  | to |  7300  done\n",
      "7300  | to |  7400  done\n",
      "7400  | to |  7500  done\n",
      "7500  | to |  7600  done\n",
      "7600  | to |  7700  done\n",
      "7700  | to |  7800  done\n",
      "7800  | to |  7900  done\n",
      "7900  | to |  8000  done\n",
      "8000  | to |  8100  done\n",
      "8100  | to |  8200  done\n",
      "8200  | to |  8300  done\n",
      "8300  | to |  8400  done\n",
      "8400  | to |  8500  done\n",
      "8500  | to |  8600  done\n",
      "8600  | to |  8700  done\n",
      "8700  | to |  8800  done\n",
      "8800  | to |  8900  done\n",
      "8900  | to |  9000  done\n",
      "9000  | to |  9100  done\n",
      "9100  | to |  9200  done\n",
      "9200  | to |  9300  done\n",
      "9300  | to |  9400  done\n",
      "9400  | to |  9500  done\n",
      "9500  | to |  9600  done\n",
      "9600  | to |  9700  done\n",
      "9700  | to |  9800  done\n",
      "9800  | to |  9900  done\n",
      "9900  | to |  10000  done\n",
      "10000  | to |  10100  done\n",
      "10100  | to |  10200  done\n",
      "10200  | to |  10300  done\n",
      "10300  | to |  10400  done\n",
      "10400  | to |  10500  done\n",
      "10500  | to |  10600  done\n",
      "10600  | to |  10700  done\n",
      "10700  | to |  10800  done\n",
      "10800  | to |  10900  done\n",
      "10900  | to |  11000  done\n",
      "11000  | to |  11100  done\n",
      "11100  | to |  11200  done\n",
      "11200  | to |  11300  done\n",
      "11300  | to |  11400  done\n",
      "11400  | to |  11500  done\n",
      "11500  | to |  11600  done\n",
      "11600  | to |  11700  done\n",
      "11700  | to |  11800  done\n",
      "11800  | to |  11900  done\n",
      "11900  | to |  12000  done\n",
      "12000  | to |  12100  done\n",
      "12100  | to |  12200  done\n",
      "12200  | to |  12300  done\n",
      "12300  | to |  12400  done\n",
      "12400  | to |  12500  done\n",
      "12500  | to |  12600  done\n",
      "12600  | to |  12700  done\n",
      "12700  | to |  12800  done\n",
      "12800  | to |  12900  done\n",
      "12900  | to |  13000  done\n",
      "13000  | to |  13100  done\n",
      "13100  | to |  13200  done\n",
      "13200  | to |  13300  done\n",
      "13300  | to |  13400  done\n",
      "13400  | to |  13500  done\n",
      "13500  | to |  13600  done\n",
      "13600  | to |  13700  done\n",
      "13700  | to |  13800  done\n",
      "13800  | to |  13900  done\n",
      "13900  | to |  14000  done\n",
      "14000  | to |  14100  done\n",
      "14100  | to |  14200  done\n",
      "14200  | to |  14300  done\n",
      "14300  | to |  14400  done\n",
      "14400  | to |  14500  done\n",
      "14500  | to |  14600  done\n",
      "14600  | to |  14700  done\n",
      "14700  | to |  14800  done\n",
      "14800  | to |  14900  done\n",
      "14900  | to |  15000  done\n",
      "15000  | to |  15100  done\n",
      "15100  | to |  15200  done\n",
      "15200  | to |  15300  done\n",
      "15300  | to |  15400  done\n",
      "15400  | to |  15500  done\n",
      "15500  | to |  15600  done\n",
      "15600  | to |  15700  done\n",
      "15700  | to |  15800  done\n",
      "15800  | to |  15900  done\n",
      "15900  | to |  16000  done\n",
      "16000  | to |  16100  done\n",
      "16100  | to |  16200  done\n",
      "16200  | to |  16300  done\n",
      "16300  | to |  16400  done\n",
      "16400  | to |  16500  done\n",
      "16500  | to |  16600  done\n",
      "16600  | to |  16700  done\n",
      "16700  | to |  16800  done\n",
      "16800  | to |  16900  done\n",
      "16900  | to |  17000  done\n",
      "17000  | to |  17100  done\n",
      "17100  | to |  17200  done\n",
      "17200  | to |  17300  done\n",
      "17300  | to |  17400  done\n",
      "17400  | to |  17500  done\n",
      "17500  | to |  17600  done\n",
      "17600  | to |  17700  done\n",
      "17700  | to |  17800  done\n",
      "17800  | to |  17900  done\n",
      "17900  | to |  18000  done\n",
      "18000  | to |  18100  done\n",
      "18100  | to |  18200  done\n",
      "18200  | to |  18300  done\n",
      "18300  | to |  18400  done\n",
      "18400  | to |  18500  done\n",
      "18500  | to |  18600  done\n",
      "18600  | to |  18700  done\n",
      "18700  | to |  18800  done\n",
      "18800  | to |  18900  done\n",
      "18900  | to |  19000  done\n",
      "19000  | to |  19100  done\n",
      "19100  | to |  19200  done\n",
      "19200  | to |  19300  done\n",
      "19300  | to |  19400  done\n",
      "19400  | to |  19500  done\n",
      "19500  | to |  19600  done\n",
      "19600  | to |  19700  done\n",
      "19700  | to |  19800  done\n",
      "19800  | to |  19900  done\n",
      "19900  | to |  20000  done\n",
      "20000  | to |  20100  done\n",
      "20100  | to |  20200  done\n",
      "20200  | to |  20300  done\n",
      "20300  | to |  20400  done\n",
      "20400  | to |  20500  done\n",
      "20500  | to |  20600  done\n",
      "20600  | to |  20700  done\n",
      "20700  | to |  20800  done\n",
      "20800  | to |  20900  done\n",
      "20900  | to |  21000  done\n",
      "21000  | to |  21100  done\n",
      "21100  | to |  21200  done\n",
      "21200  | to |  21300  done\n",
      "21300  | to |  21400  done\n",
      "21400  | to |  21500  done\n",
      "21500  | to |  21600  done\n",
      "21600  | to |  21700  done\n",
      "21700  | to |  21800  done\n",
      "21800  | to |  21900  done\n",
      "21900  | to |  22000  done\n",
      "torch.Size([60, 1, 30, 800])\n",
      "torch.Size([60, 60, 9])\n",
      "torch.Size([60])\n",
      "max_image_length:  800\n",
      "max_label_length:  42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "Images = []\n",
    "Labels = []\n",
    "\n",
    "label_lengths = []\n",
    "\n",
    "number_of_data_points = 0\n",
    "\n",
    "max_image_length = 0\n",
    "max_label_length = 0\n",
    "\n",
    "num = 1\n",
    "\n",
    "lines = read_file_lines(\"../teluguOCR/Dataset/strings.txt\")\n",
    "for i in range(30000):\n",
    "    full_label = torch.zeros(60, 9)\n",
    "    image = torch.load(\"/home/ocr/teluguOCR/Dataset/Noised_Images/Image\" + str(i+1) + \".pt\")\n",
    "\n",
    "\n",
    "    label = index_encoding(lines[i])\n",
    "    label = torch.tensor(label)\n",
    "\n",
    "    if image.shape[1] > 800 or label.shape[0] > 45:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    full_image = torch.zeros(30, 800)\n",
    "    full_image[:, :image.shape[1]] = image[:, :]\n",
    "    image = full_image\n",
    "\n",
    "    img = Image.fromarray(image.numpy())\n",
    "    img = img.resize((800, 30))\n",
    "    image = torch.tensor(np.array(img))\n",
    "\n",
    "    label_lengths.append(label.shape[0])\n",
    "\n",
    "    max_image_length = max(max_image_length, image.shape[1])\n",
    "    max_label_length = max(max_label_length, label.shape[0])\n",
    "\n",
    "    Images.append(image.unsqueeze(0))\n",
    "    \n",
    "    full_label[:label.shape[0], :] = label[:, :]\n",
    "\n",
    "    Labels.append(full_label)\n",
    "    number_of_data_points += 1\n",
    "\n",
    "    if len(Images) == 100:\n",
    "        Images = torch.stack(Images)\n",
    "        Labels = torch.stack(Labels)\n",
    "        labels_lengths = torch.tensor(label_lengths)\n",
    "        torch.save(Images, \"/home/ocr/teluguOCR/Dataset/Full_Image_Tensors/Full_Image_Tensors\"+ str(num) +\".pt\")\n",
    "        torch.save(Labels, \"/home/ocr/teluguOCR/Dataset/Full_Label_Tensors/Full_Label_Tensors\" + str(num) + \".pt\")\n",
    "        torch.save(labels_lengths, \"/home/ocr/teluguOCR/Dataset/Full_label_length_tensors/Full_Label_Lengths\" + str(num) + \".pt\")\n",
    "        print(100*num , \" | to | \", 100*(num+1), \" done\")\n",
    "        Images = []\n",
    "        Labels = []\n",
    "        label_lengths = []\n",
    "        num += 1\n",
    "\n",
    "if len(Images) != 0:\n",
    "    Images = torch.stack(Images)\n",
    "    Labels = torch.stack(Labels)\n",
    "    labels_lengths = torch.tensor(label_lengths)\n",
    "    torch.save(Images, \"/home/ocr/teluguOCR/Dataset/Full_Image_Tensors/Full_Image_Tensors\"+ str(num) +\".pt\")\n",
    "    torch.save(Labels, \"/home/ocr/teluguOCR/Dataset/Full_Label_Tensors/Full_Label_Tensors\" + str(num) + \".pt\")\n",
    "    torch.save(labels_lengths, \"/home/ocr/teluguOCR/Dataset/Full_label_length_tensors/Full_Label_Lengths\" + str(num) + \".pt\")\n",
    "    print(100*num , \" | to | \", 100*(num+1), \" done\")\n",
    "\n",
    "# Images = torch.stack(Images)\n",
    "# Labels = torch.stack(Labels)\n",
    "# labels_lengths = torch.tensor(label_lengths)\n",
    "\n",
    "print(Images.shape)\n",
    "print(Labels.shape)\n",
    "print(labels_lengths.shape)\n",
    "\n",
    "print(\"max_image_length: \", max_image_length)\n",
    "print(\"max_label_length: \", max_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21860\n"
     ]
    }
   ],
   "source": [
    "print(number_of_data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m Images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ocr/teluguOCR/Dataset/Noised_Images/Image300.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mImages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     12\u001b[0m full \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m1200\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "Images = torch.load(\"/home/ocr/teluguOCR/Dataset/Noised_Images/Image300.pt\")\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(Images[0, :, :], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "full = torch.zeros(30, 1200)\n",
    "full[:, :Images.shape[2]] = Images\n",
    "\n",
    "print(full.shape)\n",
    "\n",
    "img = Image.fromarray(full.numpy())\n",
    "\n",
    "img = img.resize((500, 10))\n",
    "full = torch.tensor(np.array(img))\n",
    "print(full.shape)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(full[:, :], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# lengths = []\n",
    "\n",
    "# for i in range(1, 30001):\n",
    "#     image = torch.load(\"/home/ocr/teluguOCR/Dataset/Noised_Images/Image\" + str(i) + \".pt\")\n",
    "#     # if image.shape[2] > 1200:\n",
    "#     #     continue\n",
    "#     lengths.append(image.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = read_file_lines(\"../teluguOCR/Dataset/strings.txt\")\n",
    "lebel_lengths = torch.load(\"../teluguOCR/Dataset/Full_label_length_tensors/Full_Label_Lengths1.pt\")\n",
    "\n",
    "for i in range(100):\n",
    "    # print(i,\" | \", labels[i])\n",
    "    List = wordsDicts(labels[i])\n",
    "    print(len(List) == lebel_lengths[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teluguOCR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
